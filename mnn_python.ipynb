{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krUsgITcC_yR"
      },
      "outputs": [],
      "source": [
        "!pip3 install MNN opencv-python numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Cvf24eC4IT",
        "outputId": "2d66ccd4-089c-4201-d687-647e64c2324f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib_RmmY7JL9m",
        "outputId": "40507727-fdd3-45a8-fc29-95c1a7ee4af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/mnn\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/mnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOugZ01AIGge"
      },
      "outputs": [],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U MNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "6MkNh_G0IDN9",
        "outputId": "b0a05dd5-5d4d-4aa8-9451-7f40befe328c"
      },
      "outputs": [],
      "source": [
        "# Copyright @ 2020 Alibaba. All rights reserved.\n",
        "# Created by ruhuan on 2020.09.17\n",
        "# Part of demo resource comes from MNN contributor, see below link FYI. \n",
        "# https://github.com/xindongzhang/MNN-APPLICATIONS\n",
        "\"\"\" python demo usage about multi-input/multi-output MNN API \"\"\"\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import MNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jp0sGnlaDPga",
        "outputId": "aebcf8f0-f3ea-4d2c-a72e-b6f042a426d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inference():\n",
        "    \"\"\" inference face detect using a specific picture\n",
        "        \n",
        "        the face detect network's backbone is mobile-ssd w/ two outputs tensors.\n",
        "    \"\"\"\n",
        "    #create the MNN interpreter from model file\n",
        "    interpreter = MNN.Interpreter(\"/content/drive/MyDrive/mnn/ssrnet.mnn\")\n",
        "    \n",
        "    #create the MNN session by using MNN interpreter\n",
        "    session = interpreter.createSession()\n",
        "    \n",
        "    #get the input dict from the session \n",
        "    inputs = interpreter.getSessionInputAll(session)\n",
        "    \n",
        "    #get the output dict from the session \n",
        "    outputs = interpreter.getSessionOutputAll(session)\n",
        "    \n",
        "    #get the input/output tensors from the dict \n",
        "    input0 = inputs['normalized_input_image_tensor']\n",
        "    output0 = outputs['concat']\n",
        "    output1 = outputs['concat_1']\n",
        "    \n",
        "    #cv2 read as bgr format\n",
        "    ori_image = cv2.imread('/content/drive/MyDrive/mnn/r1.jpg')\n",
        "    plt.title(\"input image\")\n",
        "    plt.imshow(ori_image[:,:,[2,1,0]])\n",
        "    plt.show()\n",
        "    \n",
        "    #change to rgb format\n",
        "    image = ori_image[..., ::-1]\n",
        "    \n",
        "    #resize to mobile_net tensor size\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    \n",
        "    #preprocess it\n",
        "    image = (image - 123.) / 58. \n",
        "   \n",
        "    #as cv2 read shape is NHWC, Tensor's need is NCHW,transpose it\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    \n",
        "    #change numpy data type as np.float32 to match tensor's format\n",
        "    image = image.astype(np.float32)\n",
        "    \n",
        "    #create temporary tensors for copy in/out \n",
        "    tmp_input0 = MNN.Tensor((1, 3, 224, 224), MNN.Halide_Type_Float,\\\n",
        "                    image, MNN.Tensor_DimensionType_Caffe)\n",
        "    tmp_output0 = MNN.Tensor((1, 1014, 2), MNN.Halide_Type_Float,\\\n",
        "                    tuple(1 * 1014 * 2 *[1.0]), MNN.Tensor_DimensionType_Caffe)\n",
        "    tmp_output1 = MNN.Tensor((1, 4, 1014, 1), MNN.Halide_Type_Float,\\\n",
        "                    tuple(1 * 4 * 1014 * 1 *[1.0]), MNN.Tensor_DimensionType_Caffe)\n",
        "    \n",
        "    #copy tensors values as inputs \n",
        "    input0.copyFrom(tmp_input0)\n",
        " \n",
        "    \n",
        "    #run session\n",
        "    interpreter.runSession(session)\n",
        "    \n",
        "    #copy tensors value as outputs\n",
        "    output0.copyToHostTensor(tmp_output0)\n",
        "    output1.copyToHostTensor(tmp_output1)\n",
        "    \n",
        "    #get output data\n",
        "    scores = tmp_output0.getData()\n",
        "    boxes = tmp_output1.getData()\n",
        "    \n",
        "    #as the orignal tensors are [1, 1014, 2], [1, 4, 1014, 1], we reshape them\n",
        "    scores = scores.reshape([2, 1014])\n",
        "    boxes = boxes.reshape([4, 1014])\n",
        "\n",
        "    print(scores,boxes)\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    #contant values for anchors and scales\n",
        "    face_prob_thresh = 0.3\n",
        "    max_prob = 0.\n",
        "    anchors = np.load(\"/content/drive/My Drive/MNN-tutorial/facedetection_tutorial/resource/anchors.npy\")\n",
        "    X_SCALE    = 10.0\n",
        "    Y_SCALE    = 10.0\n",
        "    H_SCALE    = 5.0\n",
        "    W_SCALE    = 5.0\n",
        "    \n",
        "    #loop and find the face w/ most probability\n",
        "    for i in range(1014):\n",
        "        ycenter = boxes[0][i] / Y_SCALE * anchors[2][i] + anchors[0][i]\n",
        "        xcenter = boxes[1][i] / X_SCALE * anchors[3][i] + anchors[1][i]\n",
        "        h = np.exp(boxes[2][i] / H_SCALE) * anchors[2][i]\n",
        "        w = np.exp(boxes[3][i] / W_SCALE) * anchors[3][i]\n",
        "        ymin    = ( ycenter - h * 0.5 ) * ori_image.shape[0];\n",
        "        xmin    = ( xcenter - w * 0.5 ) * ori_image.shape[1];\n",
        "        ymax    = ( ycenter + h * 0.5 ) * ori_image.shape[0];\n",
        "        xmax    = ( xcenter + w * 0.5 ) * ori_image.shape[1];\n",
        "        nonface_prob = np.exp(scores[0][i])\n",
        "        face_prob = np.exp(scores[1][i])\n",
        "        ss = nonface_prob + face_prob\n",
        "        nonface_prob /= ss\n",
        "        face_prob /= ss\n",
        "        if face_prob > face_prob_thresh and face_prob_thresh > max_prob:\n",
        "            if xmin > 0 and ymin > 0 and xmax < ori_image.shape[1] and ymax < ori_image.shape[0]:\n",
        "                max_prob = face_prob\n",
        "                pt1 = (int(xmin), int(ymin))\n",
        "                pt2 = (int(xmax), int(ymax))\n",
        "    cv2.rectangle(ori_image, pt1, pt2, (255, 0, 0), 2)\n",
        "    plt.title(\"result image\")\n",
        "    plt.imshow(ori_image[:,:,[2,1,0]])\n",
        "    plt.show()    '''\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    inference()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
